{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "present-brown",
   "metadata": {},
   "source": [
    "# HW09: Transformers\n",
    "\n",
    "Remember that these homework work as a completion grade. **You can skip one section of this homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "irish-ending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20620</th>\n",
       "      <td>sci/tech</td>\n",
       "      <td>RFID tags: The people say no</td>\n",
       "      <td>The issue has united readers of all stripes, f...</td>\n",
       "      <td>RFID tags: The people say no The issue has uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66604</th>\n",
       "      <td>business</td>\n",
       "      <td>Computer Associates Results Top View (Reuters)</td>\n",
       "      <td>Reuters - Computer Associates International Lt...</td>\n",
       "      <td>Computer Associates Results Top View (Reuters)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116589</th>\n",
       "      <td>business</td>\n",
       "      <td>Brazil corruption charges urged</td>\n",
       "      <td>More than 90 people in Brazil face possible ch...</td>\n",
       "      <td>Brazil corruption charges urged More than 90 p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115889</th>\n",
       "      <td>sport</td>\n",
       "      <td>Compiled by Page 3</td>\n",
       "      <td>With real life news reading funnier than made-...</td>\n",
       "      <td>Compiled by Page 3 With real life news reading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78872</th>\n",
       "      <td>world</td>\n",
       "      <td>Arafat condition improves, illness still a mys...</td>\n",
       "      <td>PARIS Palestinian officials say a medical repo...</td>\n",
       "      <td>Arafat condition improves, illness still a mys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                              title  \\\n",
       "20620   sci/tech                       RFID tags: The people say no   \n",
       "66604   business     Computer Associates Results Top View (Reuters)   \n",
       "116589  business                    Brazil corruption charges urged   \n",
       "115889     sport                                 Compiled by Page 3   \n",
       "78872      world  Arafat condition improves, illness still a mys...   \n",
       "\n",
       "                                                     lead  \\\n",
       "20620   The issue has united readers of all stripes, f...   \n",
       "66604   Reuters - Computer Associates International Lt...   \n",
       "116589  More than 90 people in Brazil face possible ch...   \n",
       "115889  With real life news reading funnier than made-...   \n",
       "78872   PARIS Palestinian officials say a medical repo...   \n",
       "\n",
       "                                                     text  \n",
       "20620   RFID tags: The people say no The issue has uni...  \n",
       "66604   Computer Associates Results Top View (Reuters)...  \n",
       "116589  Brazil corruption charges urged More than 90 p...  \n",
       "115889  Compiled by Page 3 With real life news reading...  \n",
       "78872   Arafat condition improves, illness still a mys...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.columns = [\"label\", \"title\", \"lead\"]\n",
    "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
    "def replace_label(x):\n",
    "\treturn label_map[x]\n",
    "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
    "df = df.sample(n=10000) # # only use 10K datapoints\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-klein",
   "metadata": {},
   "source": [
    "## Hugginface Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reasonable-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-05-12 15:21:06.566067: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-12 15:21:06.566133: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-05-12 15:21:10.399576: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-12 15:21:10.399632: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-12 15:21:10.399672: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Henry): /proc/driver/nvidia/version does not exist\n",
      "2022-05-12 15:21:10.399942: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-12 15:21:10.432299: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_transform', 'vocab_layer_norm', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification, DistilBertConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
    "config.num_labels = 4\n",
    "transformer_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confident-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO build a transformer model to do sequence classification with the goal to predict the label from the text\n",
    "\n",
    "seq_len = 256 # use masking for padded sequences of length 256\n",
    "input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "input_masks_ids = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# build model to handle input tokens and masks\n",
    "X = transformer_model(input_ids, input_masks_ids)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "psychological-object",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_distil_bert_for_sequence_cl  TFSequenceClassifie  66956548   ['input_ids[0][0]',              \n",
      " assification (TFDistilBertForS  rOutput(loss=None,               'attention_mask[0][0]']         \n",
      " equenceClassification)         logits=(None, 4),                                                 \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66,956,548\n",
      "Trainable params: 66,956,548\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##TODO print the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deadly-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', # cost function\n",
    "              optimizer='adam', # use adam as the optimizer\n",
    "              metrics=['accuracy']) # compute accuracy, for scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-packet",
   "metadata": {},
   "source": [
    "**Hint:** All the vectorized pieces of text must have the same length (which will be equal to the input size). You have two options to ensure this:\n",
    "\n",
    "1. Set the maximum length equal to the length of the shortest vectorized text\n",
    "2. Choose the maximum length and then exclude all the data points that have vectors shorter than that length\n",
    "\n",
    "**Hint:** Tensorflow requires your labels to be integers, not strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "statistical-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO split the sample into a training and a test set \n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'].tolist(), df['label'].tolist(), test_size=.2)\n",
    "\n",
    "labelEncoder = LabelEncoder().fit(df['label'])\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "##TODO prepare the dataset for tensorflow.\n",
    "def prepare_ds(X, y):\n",
    "    # tokenize dataset and get integer labels\n",
    "    X_tf = tokenizer(X, return_tensors=\"tf\", padding=True, truncation=True, max_length=seq_len)\n",
    "    y_tf = labelEncoder.transform(y)\n",
    "\n",
    "    # build batched tensorflow dataset\n",
    "    return tf.data.Dataset.from_tensor_slices((dict(X_tf), y_tf)).batch(8)\n",
    "\n",
    "train_ds = prepare_ds(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "piano-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO fit the model and print the obtained accuracy\n",
    "model.fit(train_ds, epochs=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa312bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test split\n",
    "test_ds = prepare_ds(X_test, y_test)\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe3a17",
   "metadata": {},
   "source": [
    "# LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "##TODO create a sequential model with an embedding layer, a LSTM layer and two hidden layers with ReLu activation function, followed by dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3560a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO compile the model and fit it to predict the business label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
