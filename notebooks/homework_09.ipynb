{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "present-brown",
      "metadata": {
        "id": "present-brown"
      },
      "source": [
        "# HW09: Transformers\n",
        "\n",
        "Remember that these homework work as a completion grade. **You can skip one section of this homework.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
        "#!pip install transformers\n",
        "#!pip install scikit-learn"
      ],
      "metadata": {
        "id": "A1FtbYM9dUEL"
      },
      "id": "A1FtbYM9dUEL",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "irish-ending",
      "metadata": {
        "id": "irish-ending",
        "outputId": "c685618b-973e-44ca-96cc-f42659318356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N_SAMPLES: 10000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          label                                              title  \\\n",
              "18373     sport            Decision appealing for Kapler and Nixon   \n",
              "84421     world             Strong Earthquake Jolts Northern Japan   \n",
              "25686  sci/tech  Will Expand Beyond's Patents Lead to New Partn...   \n",
              "42984     sport  American Express Cship: Woods eyes fourth titl...   \n",
              "93063     world       Congress Ready to Update Special Ed Law (AP)   \n",
              "\n",
              "                                                    lead  \\\n",
              "18373  Beware, titans of the legal world. There may b...   \n",
              "84421   TOKYO (Reuters) - A strong earthquake with a ...   \n",
              "25686  Ziff Davis - Wireless software provider Expand...   \n",
              "42984  LONDON: Three-times winner Tiger Woods bids fo...   \n",
              "93063  AP - Congressional negotiators have reached ag...   \n",
              "\n",
              "                                                    text  \n",
              "18373  Decision appealing for Kapler and Nixon Beware...  \n",
              "84421  Strong Earthquake Jolts Northern Japan  TOKYO ...  \n",
              "25686  Will Expand Beyond's Patents Lead to New Partn...  \n",
              "42984  American Express Cship: Woods eyes fourth titl...  \n",
              "93063  Congress Ready to Update Special Ed Law (AP) A...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6a8e8bc-42e6-4742-ae44-c1a23bfd3cd2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>lead</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18373</th>\n",
              "      <td>sport</td>\n",
              "      <td>Decision appealing for Kapler and Nixon</td>\n",
              "      <td>Beware, titans of the legal world. There may b...</td>\n",
              "      <td>Decision appealing for Kapler and Nixon Beware...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84421</th>\n",
              "      <td>world</td>\n",
              "      <td>Strong Earthquake Jolts Northern Japan</td>\n",
              "      <td>TOKYO (Reuters) - A strong earthquake with a ...</td>\n",
              "      <td>Strong Earthquake Jolts Northern Japan  TOKYO ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25686</th>\n",
              "      <td>sci/tech</td>\n",
              "      <td>Will Expand Beyond's Patents Lead to New Partn...</td>\n",
              "      <td>Ziff Davis - Wireless software provider Expand...</td>\n",
              "      <td>Will Expand Beyond's Patents Lead to New Partn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42984</th>\n",
              "      <td>sport</td>\n",
              "      <td>American Express Cship: Woods eyes fourth titl...</td>\n",
              "      <td>LONDON: Three-times winner Tiger Woods bids fo...</td>\n",
              "      <td>American Express Cship: Woods eyes fourth titl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93063</th>\n",
              "      <td>world</td>\n",
              "      <td>Congress Ready to Update Special Ed Law (AP)</td>\n",
              "      <td>AP - Congressional negotiators have reached ag...</td>\n",
              "      <td>Congress Ready to Update Special Ed Law (AP) A...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6a8e8bc-42e6-4742-ae44-c1a23bfd3cd2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6a8e8bc-42e6-4742-ae44-c1a23bfd3cd2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6a8e8bc-42e6-4742-ae44-c1a23bfd3cd2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "N_SAMPLES = 10000 # only use N_SAMPLES datapoints\n",
        "SEQLEN = 256 \t\t\t# use masking for padded sequences of length 256\n",
        "N_EPOCHS = 2\t\t\t# train for N_EPOCHS\n",
        "BATCHSIZE = 16\t\t# use batchsize\n",
        "\n",
        "df.columns = [\"label\", \"title\", \"lead\"]\n",
        "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
        "def replace_label(x):\n",
        "\treturn label_map[x]\n",
        "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
        "df = df.sample(n=N_SAMPLES) \n",
        "print(f'N_SAMPLES: {df.shape[0]}')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "regulated-klein",
      "metadata": {
        "id": "regulated-klein"
      },
      "source": [
        "## Hugginface Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "reasonable-graph",
      "metadata": {
        "id": "reasonable-graph",
        "outputId": "993be06e-f514-4efa-b8e7-9ce1756a2beb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'dropout_19', 'pre_classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from transformers import TFDistilBertForSequenceClassification, DistilBertConfig\n",
        "import tensorflow as tf\n",
        "\n",
        "config = DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
        "config.num_labels = 4\n",
        "transformer_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
        "\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model.summary()"
      ],
      "metadata": {
        "id": "IsmtD5H4kRVW",
        "outputId": "8ea7040d-63b5-4919-d554-f85a5601f618",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IsmtD5H4kRVW",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " distilbert (TFDistilBertMai  multiple                 66362880  \n",
            " nLayer)                                                         \n",
            "                                                                 \n",
            " pre_classifier (Dense)      multiple                  590592    \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  3076      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,956,548\n",
            "Trainable params: 66,956,548\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "confident-village",
      "metadata": {
        "id": "confident-village"
      },
      "outputs": [],
      "source": [
        "##TODO build a transformer model to do sequence classification with the goal to predict the label from the text\n",
        "\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQLEN,), name='input_ids', dtype='int32')\n",
        "input_masks_ids = tf.keras.layers.Input(shape=(SEQLEN,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# freeze pretrained weights to tune only classification head\n",
        "transformer_model.distilbert.trainable = False \n",
        "\n",
        "# build model to handle input tokens and masks\n",
        "X = transformer_model(input_ids, input_masks_ids)\n",
        "model = tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "psychological-object",
      "metadata": {
        "id": "psychological-object",
        "outputId": "d9b5a54e-8c06-4a40-e53b-0ac47d71f4ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_for_sequence_cl  TFSequenceClassifie  66956548   ['input_ids[0][0]',              \n",
            " assification (TFDistilBertForS  rOutput(loss=None,               'attention_mask[0][0]']         \n",
            " equenceClassification)         logits=(None, 4),                                                 \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,956,548\n",
            "Trainable params: 593,668\n",
            "Non-trainable params: 66,362,880\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "##TODO print the summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "deadly-escape",
      "metadata": {
        "id": "deadly-escape"
      },
      "outputs": [],
      "source": [
        "##TODO compile the model\n",
        "from tensorflow.keras import optimizers, losses\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=3e-5) # use adam as the optimizer\n",
        "loss = losses.SparseCategoricalCrossentropy(from_logits=True) # cost function\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy']) # compute accuracy, for scoring\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy']) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "extra-packet",
      "metadata": {
        "id": "extra-packet"
      },
      "source": [
        "**Hint:** All the vectorized pieces of text must have the same length (which will be equal to the input size). You have two options to ensure this:\n",
        "\n",
        "1. Set the maximum length equal to the length of the shortest vectorized text\n",
        "2. Choose the maximum length and then exclude all the data points that have vectors shorter than that length\n",
        "\n",
        "**Hint:** Tensorflow requires your labels to be integers, not strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "statistical-recommendation",
      "metadata": {
        "id": "statistical-recommendation",
        "outputId": "fc5ba3db-901f-4a10-d734-4ebab8b5d885",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8000 2000 8000 2000\n"
          ]
        }
      ],
      "source": [
        "##TODO split the sample into a training and a test set \n",
        "from transformers import DistilBertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'].tolist(), df['label'].tolist(), test_size=.2)\n",
        "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
        "\n",
        "labelEncoder = LabelEncoder().fit(df['label'])\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "##TODO prepare the dataset for tensorflow.\n",
        "def prepare_ds(X, y):\n",
        "    # tokenize dataset and get integer labels\n",
        "    X_tf = tokenizer(X, return_tensors=\"tf\", padding=True, truncation=True, max_length=SEQLEN)\n",
        "    y_tf = labelEncoder.transform(y)\n",
        "\n",
        "    # build batched tensorflow dataset\n",
        "    return tf.data.Dataset.from_tensor_slices((dict(X_tf), y_tf)).batch(BATCHSIZE)\n",
        "\n",
        "train_ds = prepare_ds(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "piano-compound",
      "metadata": {
        "id": "piano-compound",
        "outputId": "997f030c-1228-4172-9d84-b04a4c3004e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "500/500 [==============================] - 85s 158ms/step - loss: 1.4554 - accuracy: 0.3217\n",
            "Epoch 2/2\n",
            "500/500 [==============================] - 79s 158ms/step - loss: 1.3863 - accuracy: 0.3176\n"
          ]
        }
      ],
      "source": [
        "##TODO fit the model and print the obtained accuracy\n",
        "hist = model.fit(train_ds, epochs=N_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "baa312bb",
      "metadata": {
        "id": "baa312bb",
        "outputId": "3124783f-d700-469e-b865-aedb6f6d84d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 18s 146ms/step - loss: 1.3863 - accuracy: 0.2790\n",
            "accuracy: 0.27900001406669617\n"
          ]
        }
      ],
      "source": [
        "# evaluate model on test split\n",
        "test_ds = prepare_ds(X_test, y_test)\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "\n",
        "print(f'accuracy: {acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7fe3a17",
      "metadata": {
        "id": "e7fe3a17"
      },
      "source": [
        "# LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d4ff5fb2",
      "metadata": {
        "id": "d4ff5fb2"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM\n",
        "\n",
        "##TODO create a sequential model with an embedding layer, a LSTM layer and two hidden layers with ReLu activation function, followed by dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b3560a5c",
      "metadata": {
        "id": "b3560a5c"
      },
      "outputs": [],
      "source": [
        "##TODO compile the model and fit it to predict the business label"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "homework_09.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}