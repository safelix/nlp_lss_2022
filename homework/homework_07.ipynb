{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f0f784c",
   "metadata": {},
   "source": [
    "# HW07: Document Embeddings \n",
    "\n",
    "Remember that these homework work as a completion grade. **In this homework, we present two tasks and you can choose which one you want to solve. You only have to solve <span style=\"color:red\">one task</span> in this homework.**\n",
    "Task 1 is more guided and we evaluate document embeddings on a standard benchmark. Task 2 is very open-end and might be a starting point for your course project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1615f",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "In this task, we evaluate different document embeddings on the English version of the [STS Benchmark](https://arxiv.org/pdf/1708.00055.pdf). The task is to determine how semantically similar two texts are and is a popular dataset to evaluate document embeddings, i.e. we want embeddings of two semantically similar documents to be similar as well. We provide a wordcounts baseline for this task and ask you to compute and evaluate embeddings for a selected sample of document embedding techniques.\n",
    "\n",
    "To evaluate, we follow [(Reimers and Gurevych, 2019)](https://arxiv.org/pdf/1908.10084.pdf) and compute the Spearmanâ€™s rank correlation between the cosine-similarity of thesentence embeddings and the gold labels. **It is ok to skip one of the document embedding methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde54669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the data\n",
    "#!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip\n",
    "#!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip\n",
    "\n",
    "#!unzip sts2017.eval.v1.1.zip \n",
    "#!unzip sts2017.gs.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122aef7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A person is on a baseball team.',\n",
       " 'A person is playing basketball on a team.',\n",
       " 2.4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "\n",
    "def load_STS_data():\n",
    "    with open(\"STS2017.gs/STS.gs.track5.en-en.txt\") as f:\n",
    "        labels = [float(line.strip()) for line in f]\n",
    "    \n",
    "    text_a, text_b = [], []\n",
    "    with open(\"STS2017.eval.v1.1/STS.input.track5.en-en.txt\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            text_a.append(line[0])\n",
    "            text_b.append(line[1])\n",
    "    return text_a, text_b, labels\n",
    "\n",
    "text_a, text_b, labels = load_STS_data()\n",
    "text_a[0], text_b[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71472b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utils\n",
    "from scipy.stats import spearmanr\n",
    "def evaluate(predictions, labels):\n",
    "    print (\"spearman's rank correlation\", spearmanr(predictions, labels)[0])\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf91d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman's rank correlation 0.6998056665685976\n"
     ]
    }
   ],
   "source": [
    "# Wordcounts baseline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "vec.fit(text_a + text_b)\n",
    "\n",
    "# encode documents\n",
    "text_a_encoded = np.array(vec.transform(text_a).todense())\n",
    "text_b_encoded = np.array(vec.transform(text_b).todense())\n",
    "\n",
    "# predict cosine similarities\n",
    "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
    "\n",
    "# evaluate\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8718270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman's rank correlation 0.052841014224743035\n"
     ]
    }
   ],
   "source": [
    "##TODO train Doc2Vec on the texts in the dataset\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "doc_iterator = [TaggedDocument(doc, [i]) for i, doc in enumerate(text_a + text_b)]\n",
    "d2v = Doc2Vec(doc_iterator,\n",
    "                min_count=10, # minimum word count\n",
    "                window=10,    # window size\n",
    "                vector_size=100, # size of document vector\n",
    "                sample=1e-4, \n",
    "                negative=5, \n",
    "                workers=4, # threads\n",
    "                #dbow_words = 1 # uncomment to get word vectors too\n",
    "                max_vocab_size=1000) # max vocab size\n",
    "\n",
    "\n",
    "##TODO derive the word vectors for each text in the dataset\n",
    "##TODO compute cosine similarity between the text pairs and evaluate spearman's rank correlation\n",
    "## Don't worry if results are not satisfactory using Doc2Vec (the dataset is too small to train good embeddings)\n",
    "predictions = []\n",
    "for sent_a, sent_b in zip(text_a, text_b):\n",
    "    emb_a = d2v.infer_vector([sent_a])\n",
    "    emb_b = d2v.infer_vector([sent_b])\n",
    "    predictions.append(cosine_similarity(emb_a, emb_a))\n",
    "\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da753859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-04-28 14:50:20.893086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-28 14:50:20.893171: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman's rank correlation 0.09087822079358758\n"
     ]
    }
   ],
   "source": [
    "##TODO do the same with embeddings provided by spaCy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "predictions = []\n",
    "for sent_a, sent_b in zip(text_a, text_b):\n",
    "    emb_a = nlp(sent_a).vector\n",
    "    emb_b = nlp(sent_b).vector\n",
    "    predictions.append(cosine_similarity(emb_a, emb_a))\n",
    "\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c23d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 14:50:40.515588: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-28 14:50:40.515682: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-28 14:50:40.515785: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Henry): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "##TODO do the same with universal sentence embeddings\n",
    "#!pip install --upgrade tensorflow-hub\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "    return model(input)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c847cfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 14:50:42.459499: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman's rank correlation 0.8493103413219787\n"
     ]
    }
   ],
   "source": [
    "embs_a = embed(text_a)\n",
    "embs_b = embed(text_b)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    embs_a = session.run(embs_a)\n",
    "    embs_b = session.run(embs_b)\n",
    "\n",
    "predictions = []\n",
    "for emb_a, emb_b in zip(embs_a, embs_b):\n",
    "    predictions.append(cosine_similarity(emb_a,emb_b))\n",
    "\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86eacbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman's rank correlation 0.0530998674682112\n"
     ]
    }
   ],
   "source": [
    "##TODO do the same with SBERT embeddings\n",
    "#!pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = \"bert-base-nli-mean-tokens\"\n",
    "embedder = SentenceTransformer(model)\n",
    "\n",
    "embs_a = embedder.encode(text_a)\n",
    "embs_b = embedder.encode(text_b)\n",
    "\n",
    "predictions = []\n",
    "for emb_a, emb_b in zip(embs_b, embs_a):\n",
    "    predictions.append(cosine_similarity(emb_a, emb_a))\n",
    "\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae06d83a",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "Use your favorite document embeddings method to compute embeddings for a dataset you are interested in. Think of a method and provide some data visualization statistics (one method would be the path we have chosen in the notebook, i.e. cluster the embeddings with k-means and visualize low-dimensional representations of the document embeddings obtained by PCA). \n",
    "\n",
    "This task is very open and there is no right or wrong; If you want to use document embeddings in your course project, this is a chance to play around with them.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
