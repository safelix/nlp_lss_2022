{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed81bdc6",
   "metadata": {},
   "source": [
    "# HW12: Scientific Claim Verification\n",
    "\n",
    "**<span style=\"color:red\">Important Instructions, read carefully!</span>** \n",
    "\n",
    "* Remember that these homework work as a completion grade. The homework is structured in two parts: (1) Information Retrieval from a fact base and (2) claim verification. In case you already submitted 9 homeworks and want to only submit a 10th notebook, it is fine to just do the first part. \n",
    "\n",
    "* In this notebook, we will build an automated claim verification system for scientific claims based on the [SciFact dataset](https://arxiv.org/abs/2004.14974). \n",
    "\n",
    "* In case you need additional computational resources (GPUs), please get in touch. It is possible to solve the homework (on a downsampled dataset) without these. If you want to build really cool systems, you probably want to use the whole dataset and train models which require compute not feasible on your local machine -- get in touch.\n",
    "\n",
    "* Next, the best models to date on this dataset perform poorly. If you build a system yielding competitive scores, it is possible to do follow-up work! There exists a [global leaderboard](https://leaderboard.allenai.org/scifact/submissions/public) where you can submit test set results if you like. The [baseline system](https://arxiv.org/abs/2004.14974) achieves around 40% F1, we have built a system in January and obtain 55% F1, the [current state of the art](https://arxiv.org/pdf/2010.11930.pdf) is at around 65% F1 -- there exists ample room for improvements.\n",
    "\n",
    "* You can find the github repo for SciFact with additional information (and possibly example code which could be usueful for solving this exercise) [here](https://github.com/allenai/scifact).\n",
    "\n",
    "* For the first part of the assignment, we don't expect you to train your own transformer model, but you obviously can. For the second part of the assignment, we expect you to train your own textual entailment model.\n",
    "\n",
    "* Lastly, We don't expect you to have a competitive system at the end of this homework, anything works as long as you have put in some effort.\n",
    "\n",
    "**All instructions provided can be substituted by your own ideas and only serve as a rough guideline for how to tackle the task!**\n",
    "\n",
    "* If you want, it is also possible to build a similar system for question answering (e.g. [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/)), automated fact checking (e.g. [Climate-FEVER](https://www.sustainablefinance.uzh.ch/en/research/climate-fever.html), [FEVER](https://fever.ai/)) or other involved NLP tasks completely freestyle on a dataset of your choice. If so, please get in touch with a suggestion.\n",
    "\n",
    "* You are allowed to use any tools and help you can find online to tackle this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653efbf",
   "metadata": {},
   "source": [
    "**An Example from SciFact**\n",
    "\n",
    "Consider the claim *\"Consumption of whole fruits increases the risk of type 2 diabetes.\"*\n",
    "\n",
    "We are given a fact base of 5000 abstracts and have to find evidence from the fact base which either supports or refutes the claim. In this example, the goal is to find the following sentence from the corpus:\n",
    "\n",
    "*'Greater consumption of specific whole fruits, particularly blueberries, grapes, and apples, is significantly associated with a lower risk of type 2 diabetes, whereas greater consumption of fruit juice is associated with a higher risk.'*\n",
    "\n",
    "It is easy to see that this sentence contradicts the claim. The goal of the task is to return all sentences in the fact base which contradict or support a claim -- with the corresponding label. In this case, we would return \n",
    "\"evidence\": {\"1974176\": [{\"sentences\": [11], \"label\": \"CONTRADICT\"}\n",
    "where \"1974176\" is the doc_id of the abstract we found the evidence in, and it is the 11th sentence in that abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98f24e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-02 23:33:35--  https://scifact.s3-us-west-2.amazonaws.com/release/latest/data.tar.gz\n",
      "Resolving scifact.s3-us-west-2.amazonaws.com (scifact.s3-us-west-2.amazonaws.com)... 52.218.244.233\n",
      "Connecting to scifact.s3-us-west-2.amazonaws.com (scifact.s3-us-west-2.amazonaws.com)|52.218.244.233|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3115079 (3.0M) [application/x-tar]\n",
      "Saving to: ‘data.tar.gz’\n",
      "\n",
      "data.tar.gz         100%[===================>]   2.97M   631KB/s    in 6.8s    \n",
      "\n",
      "2022-06-02 23:33:43 (450 KB/s) - ‘data.tar.gz’ saved [3115079/3115079]\n",
      "\n",
      "._data\n",
      "data/\n",
      "data/claims_dev.jsonl\n",
      "data/cross_validation/\n",
      "data/claims_train.jsonl\n",
      "data/claims_test.jsonl\n",
      "data/corpus.jsonl\n",
      "data/cross_validation/._fold_4\n",
      "data/cross_validation/fold_4/\n",
      "data/cross_validation/fold_3/\n",
      "data/cross_validation/fold_2/\n",
      "data/cross_validation/fold_5/\n",
      "data/cross_validation/._fold_1\n",
      "data/cross_validation/fold_1/\n",
      "data/cross_validation/fold_1/claims_dev_1.jsonl\n",
      "data/cross_validation/fold_1/claims_train_1.jsonl\n",
      "data/cross_validation/fold_5/claims_train_5.jsonl\n",
      "data/cross_validation/fold_5/claims_dev_5.jsonl\n",
      "data/cross_validation/fold_2/claims_dev_2.jsonl\n",
      "data/cross_validation/fold_2/claims_train_2.jsonl\n",
      "data/cross_validation/fold_3/claims_train_3.jsonl\n",
      "data/cross_validation/fold_3/claims_dev_3.jsonl\n",
      "data/cross_validation/fold_4/claims_dev_4.jsonl\n",
      "data/cross_validation/fold_4/claims_train_4.jsonl\n"
     ]
    }
   ],
   "source": [
    "# obtain the data\n",
    "name=\"https://scifact.s3-us-west-2.amazonaws.com/release/latest/data.tar.gz\"\n",
    "!wget $name\n",
    "\n",
    "!tar -xvf data.tar.gz\n",
    "!rm data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d8df4",
   "metadata": {},
   "source": [
    "**Part 1 of the Assignment: Information Retrieval**\n",
    "\n",
    "In this section, we will build a document retrieval system which takes as input a claim and returns a number of candidate abstracts which are similar to the claim. Commonly, we start with a recall-oriented system which returns abstracts likely to contain evidence sentences. Then, we follow up with a more advanced model which selects only relevant sentences from the retrieved abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a32581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install some helper utils\n",
    "#!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6ac4464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "\n",
    "# load the corpus (the fact base with the abstracts)\n",
    "corpus = {str(doc['doc_id']): doc for doc in jsonlines.open(\"data/corpus.jsonl\")}\n",
    "\n",
    "# load the claims\n",
    "\n",
    "# if you don't want to work with GPUs , you probably want to only consider 200/50 train/dev examples\n",
    "# otherwise, this exercise might take too long\n",
    "\n",
    "cpu_only = True\n",
    "if cpu_only:\n",
    "    claims_train = [claim for claim in jsonlines.open(\"data/claims_train.jsonl\") if claim[\"evidence\"]][:200]\n",
    "    claims_dev = [claim for claim in jsonlines.open(\"data/claims_dev.jsonl\") if claim[\"evidence\"]][:50]\n",
    "else:\n",
    "    claims_train = [claim for claim in jsonlines.open(\"data/claims_train.jsonl\") if claim[\"evidence\"]][:200]\n",
    "    claims_dev = [claim for claim in jsonlines.open(\"data/claims_dev.jsonl\") if claim[\"evidence\"]][:50]\n",
    "\n",
    "print (len(claims_train))\n",
    "print (len(claims_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b174d8",
   "metadata": {},
   "source": [
    "**Inspect the data**\n",
    "\n",
    "Let's have a look at the corpus first. We see that every abstract has a unique doc_id, the title of the paper, the abstract (sentences are already tokenized) and a flag \"structured\" which is not relevant for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcea28e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents in the corpus 5183\n",
      "{'doc_id': 1974176, 'title': 'Fruit consumption and risk of type 2 diabetes: results from three prospective longitudinal cohort studies', 'abstract': ['OBJECTIVE To determine whether individual fruits are differentially associated with risk of type 2 diabetes.   \\n', 'DESIGN Prospective longitudinal cohort study.   \\n', 'SETTING Health professionals in the United States.   \\n', \"PARTICIPANTS 66,105 women from the Nurses' Health Study (1984-2008), 85,104 women from the Nurses' Health Study II (1991-2009), and 36,173 men from the Health Professionals Follow-up Study (1986-2008) who were free of major chronic diseases at baseline in these studies.   \\n\", 'MAIN OUTCOME MEASURE Incident cases of type 2 diabetes, identified through self report and confirmed by supplementary questionnaires.   \\n', 'RESULTS During 3,464,641 person years of follow-up, 12,198 participants developed type 2 diabetes.', 'After adjustment for personal, lifestyle, and dietary risk factors of diabetes, the pooled hazard ratio of type 2 diabetes for every three servings/week of total whole fruit consumption was 0.98 (95% confidence interval 0.97 [corrected] to 0.99).', 'With mutual adjustment of individual fruits, the pooled hazard ratios of type 2 diabetes for every three servings/week were 0.74 (0.66 to 0.83) for blueberries, 0.88 (0.83 to 0.93) for grapes and raisins, 0.89 (0.79 to 1.01) for prunes, 0.93 (0.90 to 0.96) for apples and pears, 0.95 (0.91 to 0.98) for bananas, 0.95 (0.91 to 0.99) for grapefruit, 0.97 (0.92 to 1.02) for peaches, plums, and apricots, 0.99 (0.95 to 1.03) for oranges, 1.03 (0.96 to 1.10) for strawberries, and 1.10 (1.02 to 1.18) for cantaloupe.', 'The pooled hazard ratio for the same increment in fruit juice consumption was 1.08 (1.05 to 1.11).', 'The associations with risk of type 2 diabetes differed significantly among individual fruits (P<0.001 in all cohorts).   \\n', 'CONCLUSION Our findings suggest the presence of heterogeneity in the associations between individual fruit consumption and risk of type 2 diabetes.', 'Greater consumption of specific whole fruits, particularly blueberries, grapes, and apples, is significantly associated with a lower risk of type 2 diabetes, whereas greater consumption of fruit juice is associated with a higher risk.'], 'structured': True}\n",
      "dict_keys(['doc_id', 'title', 'abstract', 'structured'])\n"
     ]
    }
   ],
   "source": [
    "print (\"number of documents in the corpus\", len(corpus))\n",
    "print (corpus[\"1974176\"])\n",
    "print (corpus[\"1974176\"].keys()) \n",
    "# dict_keys(['doc_id', 'title', 'abstract', 'structured'])\n",
    "# abstract is a list of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa394ae5",
   "metadata": {},
   "source": [
    "Next, we look at an example claim in more detail. We find that it has a unique id, the claim as a string and annotated evidence. The evidence is a dictionairy where each key points to the abstract in the corpus. The values are a list where each entry contains the sentence number in the corresponding abstract and a label whether this sentence contradicts or supports the claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8eef67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2, 'claim': '1 in 5 million in UK have abnormal PrP positivity.', 'evidence': {'13734012': [{'sentences': [4], 'label': 'CONTRADICT'}]}, 'cited_doc_ids': [13734012]}\n",
      "dict_keys(['id', 'claim', 'evidence', 'cited_doc_ids'])\n"
     ]
    }
   ],
   "source": [
    "print(claims_train[0])\n",
    "print(claims_train[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44364397",
   "metadata": {},
   "source": [
    "**Random Baseline for Abstract Retrieval**\n",
    "\n",
    "As mentioned before, we need a system which retrieves abstracts from the corpus. Some ideas of how to tackle this include \n",
    "* create document embeddings via TF-IDF, SBERT, universal sentence encoder or any embedding technique you like. Embedd each claim and each abstract. Then find the closest abstracts for each claim\n",
    "* use BM25 for document retrieval\n",
    "* do something else which works\n",
    "\n",
    "We provide a random baseline and evaluate recall for this method. Not surprisingly, this does not work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "864091c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random baseline\n",
    "import random\n",
    "def retrieve(claim, corpus, k):\n",
    "    return random.sample(corpus.keys(), k=k)\n",
    "\n",
    "retrieved_documents = []\n",
    "for k in (3,5,10):\n",
    "    for claim in claims_train:\n",
    "        result = retrieve(claim[\"claim\"], corpus, k)\n",
    "        claim[\"doc_ids\"] = result\n",
    "\n",
    "    for claim in claims_dev:\n",
    "        result = retrieve(claim[\"claim\"], corpus, k)\n",
    "        claim[\"doc_ids\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa32ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train claims\n",
      "precision 0 recall 0 f1 0\n",
      "dev claim\n",
      "precision 0 recall 0 f1 0\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "def evaluate(claims):\n",
    "    TP, FP, FN = 0, 0, 0\n",
    "    for claim in claims:\n",
    "        # relevant abstracts\n",
    "        if claim[\"evidence\"]:\n",
    "            true_abstracts = set(claim[\"evidence\"].keys())\n",
    "            retrieved_abstracts = set(claim[\"doc_ids\"])\n",
    "            TP += len(true_abstracts.intersection(retrieved_abstracts))\n",
    "            FN += len(true_abstracts.difference(retrieved_abstracts))\n",
    "            FP += len(retrieved_abstracts.difference(true_abstracts))\n",
    "        else:\n",
    "            FP += len(claim[\"doc_ids\"])\n",
    "    try:\n",
    "        pr = TP / (TP + FP)\n",
    "        rc = TP / (TP + FN)\n",
    "        f1 = 2 * pr * rc / (pr + rc)\n",
    "    except ZeroDivisionError:\n",
    "        pr, rc, f1 = 0,0,0\n",
    "    print (\"precision\",pr, \"recall\",rc, \"f1\",f1)\n",
    "\n",
    "print (\"train claims\")\n",
    "evaluate(claims_train)\n",
    "print (\"dev claim\")\n",
    "evaluate(claims_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16b9de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO create your own abstract retrieval system\n",
    "# Idea: Compute distilbert embedings of claims/corpus and retrieve according to cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "223fca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# gpu or cpu?\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "944f87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'distilbert-base-uncased'\n",
    "#tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "#model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "#distilbert = model.distilbert\n",
    "#print(distilbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0612ce7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='../scibert_finetuned_on_scifact', vocab_size=31090, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('../scibert_finetuned_on_scifact')\n",
    "model = BertForSequenceClassification.from_pretrained('../scibert_finetuned_on_scifact')\n",
    "bert = model.bert\n",
    "print(tokenizer)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2ba2607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Claim: 1 in 5 million in UK have abnormal PrP positivity.\n",
      "Input Tokens: {'input_ids': tensor([[  102,   158,   121,   305,  6248,   121,  4175,   360,  4592, 20112,\n",
      "         17258,   205,   103]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])} of length torch.Size([1, 13])\n",
      "Bert Output: BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-6.8391e-01,  1.0632e+00,  9.0893e-01,  ..., -6.1452e-01,\n",
      "          -1.2106e+00, -5.5906e-02],\n",
      "         [ 1.7861e+00,  1.9574e+00,  4.3740e-01,  ..., -4.6262e-01,\n",
      "          -6.0907e-01, -7.2784e-01],\n",
      "         [ 9.0921e-01,  1.1779e+00,  1.3339e+00,  ..., -8.1191e-01,\n",
      "          -1.2185e+00,  4.5049e-02],\n",
      "         ...,\n",
      "         [ 8.3025e-01,  4.6148e-01,  1.5067e+00,  ..., -8.6054e-01,\n",
      "          -5.5865e-01,  1.3873e+00],\n",
      "         [ 1.6754e+00,  1.4490e-01,  1.5846e+00,  ..., -1.4780e+00,\n",
      "          -1.7934e-03, -3.6746e-01],\n",
      "         [-3.8881e-01,  8.9272e-01,  5.1680e-01,  ..., -5.2842e-01,\n",
      "          -4.0895e-01,  1.1059e-01]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.5366,  0.2434,  0.2251,  0.9903, -0.1557, -0.1522, -0.8723, -0.8995,\n",
      "         -0.2402,  0.9460,  0.0315, -0.2910, -0.9999,  0.9776, -0.4134, -0.0922,\n",
      "          0.5308,  0.3537,  0.9770, -0.9816,  0.2688, -0.7469, -0.9994, -0.2812,\n",
      "          0.9999, -1.0000, -0.9989,  0.3603, -0.0577, -0.7796, -0.2519, -0.9772,\n",
      "         -0.3311,  0.2158, -0.1553,  0.0680, -0.1276, -0.2641,  0.0560,  0.8677,\n",
      "          0.7007, -0.0283,  0.9843, -0.2461, -0.6434,  0.6276,  0.0134, -0.4243,\n",
      "         -0.9999,  0.2709, -0.7062, -0.0520, -0.0205,  0.9802,  0.9320,  0.1182,\n",
      "          0.1080, -0.0028, -0.9430, -0.9996,  0.6687, -0.9861, -0.4194, -1.0000,\n",
      "         -0.3695, -0.2617,  0.2668,  0.2307,  0.9998, -0.3150, -0.9756, -0.0168,\n",
      "         -0.0887,  1.0000,  0.9968, -0.4685,  0.1267, -0.1558, -0.3418, -0.1893,\n",
      "         -0.2883, -0.7008,  0.3784, -0.0121, -0.1772,  0.4972, -0.1308,  0.9998,\n",
      "          0.4493,  0.0487, -0.9811,  0.9025,  0.7192,  0.3791, -0.0357,  0.0839,\n",
      "          0.1543, -0.8548, -0.6777,  0.5143,  0.4208,  0.0184, -0.7058,  0.2598,\n",
      "          0.0743,  0.5477,  0.6567,  0.4805,  0.1632,  0.8697,  0.4099,  0.1983,\n",
      "         -0.4321,  0.1771,  0.5175, -0.9490,  0.9948, -0.3137,  0.4277,  0.0949,\n",
      "         -0.1137, -0.7676,  0.8807,  0.6727,  0.2617,  0.2127,  0.3533, -0.5644,\n",
      "         -0.0762,  0.1946, -0.1266,  0.1453,  0.9055, -0.1259,  0.5863, -0.7353,\n",
      "         -0.2266,  0.3809,  0.9998,  0.2140,  0.5810, -0.1164,  0.3491, -0.5355,\n",
      "         -0.9831, -0.9912,  0.6695, -0.1583, -0.6349,  0.2190,  0.0767,  0.1917,\n",
      "          0.2003,  0.1884,  0.5919, -0.3963,  0.9999, -0.9992, -0.9996,  0.9711,\n",
      "          0.0946,  0.0621,  0.0092, -0.1945,  0.0196,  0.9976, -0.0781, -0.9724,\n",
      "          0.9948,  0.9999,  0.0828,  0.9494,  0.0315,  0.5647,  0.9738,  0.4496,\n",
      "          1.0000,  0.0857, -0.9982,  0.9269,  0.0296,  0.9819, -0.2648,  0.3094,\n",
      "         -0.4631,  0.8700,  0.0800, -0.2378,  0.6304, -0.7776,  0.0216, -0.6378,\n",
      "         -0.1242,  0.0818,  0.6704, -0.2276, -0.5215,  0.2573, -0.1261,  0.3820,\n",
      "         -0.1118, -0.9983, -0.8332,  0.8148, -0.2234, -0.2522, -0.8261, -0.4248,\n",
      "          0.6956,  0.9971,  0.9953,  0.5412,  0.3080,  0.2205, -0.9884, -0.3407,\n",
      "         -0.9988, -0.6068,  0.0091,  0.4525, -0.0515,  0.9978,  0.7297, -0.9998,\n",
      "          0.9951,  0.9382,  0.0372, -0.4739, -0.1563, -1.0000,  0.5737,  0.8864,\n",
      "          0.3349,  0.8007,  0.1616, -0.3747, -0.6177,  0.2377, -0.1021, -0.1289,\n",
      "         -0.3676,  0.4077,  0.3222,  0.4039,  0.4932, -0.6467,  0.2730, -0.5204,\n",
      "         -0.9987, -0.5478, -0.5661,  0.2185, -0.6821,  0.5478,  0.3509,  0.6193,\n",
      "          0.9594, -0.6421,  0.9880,  0.1949, -0.2608, -0.9982, -0.9999,  0.3860,\n",
      "          0.9992,  0.6911, -0.9956,  0.8803,  0.0233,  0.9986,  0.2468, -0.9989,\n",
      "         -0.9767, -0.7205,  0.3478, -0.9998,  0.2325, -0.9986,  0.2413,  0.1524,\n",
      "         -0.3546,  0.3799, -0.5492,  1.0000,  0.0182,  0.1865,  0.3401,  1.0000,\n",
      "         -0.2783, -0.1513, -0.5900, -0.9206,  0.6228,  1.0000, -0.5020,  0.3356,\n",
      "          1.0000,  0.9917,  0.9997,  0.0136,  0.5510,  0.9966, -0.3558,  0.9996,\n",
      "         -0.9998, -0.3613,  0.9931, -0.0823,  0.0050,  0.9883,  0.9954, -0.1540,\n",
      "          0.4934, -0.4295,  0.3037,  0.9905, -0.1349, -0.0261, -0.9964, -0.9707,\n",
      "         -0.0519,  0.5912,  0.1761, -0.7131,  0.9499, -0.3154, -0.6104, -0.3490,\n",
      "         -0.9862,  1.0000, -0.3610, -0.9957,  0.9071, -0.0240, -0.0451,  0.3974,\n",
      "          0.9956,  0.5202, -0.9306,  0.0422,  0.0215, -0.9999, -0.0402,  0.5471,\n",
      "         -0.5030, -0.9986,  0.2515, -0.0591,  0.2907,  0.5979, -0.4041,  0.6603,\n",
      "         -0.3295, -0.2022, -0.6001, -0.8338,  0.2464, -0.9056,  0.3394,  0.1933,\n",
      "          0.6862, -0.2104, -0.3526, -1.0000,  0.9996, -0.5680,  0.8536,  0.6625,\n",
      "         -0.3066, -0.5212, -0.1859,  0.0782,  0.0020,  0.0218, -0.8509,  0.9963,\n",
      "         -0.0629, -0.4132,  0.3237, -0.1957, -0.1895,  0.1895,  0.2833, -0.9192,\n",
      "         -0.0301, -0.3040,  0.3396,  0.0973,  0.9987,  0.9987, -0.3516,  0.0820,\n",
      "         -0.2404, -0.3819, -0.1572, -0.3032, -0.0310,  0.9751,  0.0840,  0.3462,\n",
      "          0.1268,  0.5819, -0.4140, -0.3242,  0.3357, -0.3687,  0.9996,  0.9965,\n",
      "          0.2742, -0.8184, -0.2344, -0.9903, -0.5905,  0.0553, -0.6567, -0.2957,\n",
      "          0.1404,  0.8100,  0.0319, -0.2615, -0.1635,  0.5097,  0.7767,  0.9255,\n",
      "         -0.1419, -0.3747,  0.4026, -0.1092,  0.2685,  0.1626, -0.7050, -0.0084,\n",
      "          0.6165,  0.8388, -0.9990, -0.5910,  0.8622,  0.3551,  0.6758, -0.7121,\n",
      "          0.2622, -0.0717,  0.9909, -0.9999,  0.3762, -0.5007,  0.9996, -0.5764,\n",
      "          0.9847, -0.1623, -0.4427, -0.4696, -0.2508,  0.8070,  0.9776, -0.1997,\n",
      "          0.0233, -0.9784,  0.1841,  0.4524, -0.1936, -0.1410,  0.1268, -0.9739,\n",
      "          0.0398, -0.9421,  0.3899, -0.6764,  0.3205, -0.9997,  0.9991,  0.6158,\n",
      "         -0.7114, -0.3914,  0.9990,  0.4790,  0.7908, -0.5744, -0.6887,  0.7802,\n",
      "          0.5201,  0.5784,  0.3956,  0.3335, -0.3291,  0.2542, -0.0207, -0.8845,\n",
      "         -0.9367, -0.5341, -1.0000,  0.0905,  0.6615,  0.2452,  0.9712,  0.1351,\n",
      "          0.9997, -0.7129, -0.9990, -0.2109, -0.6024, -0.7700,  0.9830, -0.1388,\n",
      "          0.2883, -0.9999,  0.9168,  0.2119, -0.9338,  0.3773, -0.3546, -0.2777,\n",
      "         -0.9284, -0.4039, -0.0855,  0.1382, -0.5568, -0.9991,  0.4026,  0.1707,\n",
      "          0.0399,  0.1383, -0.9879, -0.9999,  0.0436,  0.1318,  0.4020,  0.6719,\n",
      "          0.5367,  0.3834, -0.9626,  0.0227,  0.6682, -0.2884,  0.2659,  0.0239,\n",
      "         -0.5561, -0.9878, -0.9997,  0.4660,  0.0301,  0.5054, -0.3713, -0.9977,\n",
      "         -0.0057,  0.1428,  0.1384,  0.7711, -0.1208, -0.4263,  0.6213,  0.2030,\n",
      "         -0.0731, -0.9933,  0.9816, -0.0608,  0.5560,  0.1475, -0.0224,  0.6876,\n",
      "          0.1239,  0.0623, -0.9997, -0.2713,  0.9373, -0.1318,  0.9999, -0.9157,\n",
      "          0.5175, -0.6200, -0.1419, -0.9787, -0.1439,  0.1153, -0.1487,  0.7829,\n",
      "          0.0962, -0.9998, -0.8407,  0.1617,  0.8277,  0.8269,  0.7248,  0.9990,\n",
      "         -0.3412, -0.8704,  0.5585,  0.7305, -0.9998, -0.6807, -0.0691,  0.9991,\n",
      "         -0.9861,  0.5916, -0.1377, -0.9968,  0.2843, -0.1127,  0.3145, -0.5863,\n",
      "          0.6170, -0.0909,  0.9997,  0.3309,  0.6203, -0.9998,  0.3944, -0.2457,\n",
      "          0.8533, -0.9978,  0.2145,  0.2491,  0.5656, -0.2549,  0.4177,  0.9903,\n",
      "          0.5840,  0.2414,  0.9973,  0.5291, -0.5799, -0.9869,  0.7960,  0.2328,\n",
      "          0.1646,  0.3929,  0.9839,  0.7171, -0.3308, -0.9969, -0.9413,  0.1811,\n",
      "          0.3311, -0.5172,  0.0013, -0.9875,  0.1870,  0.0967, -0.5316, -0.4897,\n",
      "          0.9977, -0.9641,  0.1053,  0.6598, -0.1599, -0.9270, -0.7686, -0.0591,\n",
      "         -1.0000, -0.6983,  0.0091,  0.9924,  0.7583, -0.2565,  0.2561,  0.0118,\n",
      "         -0.0212,  0.1835,  0.1031,  0.2987, -0.8988,  0.4401, -0.5080,  0.2597,\n",
      "          0.3634, -0.9575,  0.4076,  0.9027,  0.1560,  0.5745,  0.2375, -0.2142,\n",
      "          0.3522, -0.9999, -0.5768,  0.9854, -0.1879,  0.6994, -0.2777,  0.9850,\n",
      "          0.9997, -0.9978, -0.7685,  0.0463, -0.9963,  0.1432,  0.8300,  0.3736,\n",
      "         -0.5636,  0.5068, -0.5738, -0.2897,  0.2327,  0.1170,  0.9391,  0.1673,\n",
      "          0.2396,  0.2775, -0.9858,  0.1167, -0.3300, -0.8411,  0.9998, -0.9983,\n",
      "          0.4146,  0.0716, -0.4920, -0.8847, -0.1108, -0.5214,  0.5669, -0.2241,\n",
      "          0.0510,  0.2166,  0.7486,  0.0636, -0.9546,  0.1853, -0.9997,  0.4147,\n",
      "          0.1261,  0.0419,  0.7046, -0.3084,  0.9984, -0.9341, -0.2894,  0.2196,\n",
      "         -0.2530, -0.8208,  0.3916, -0.6247, -0.9984,  0.2217, -0.9993, -0.9926,\n",
      "         -0.2922,  0.7069,  0.7201, -0.5680, -0.6891,  0.5382,  0.1159,  0.9928,\n",
      "          0.4620, -0.0262, -0.4543, -0.1264, -0.4803, -1.0000, -0.9938,  0.9965,\n",
      "         -0.8911,  0.9610,  0.5868, -0.2691,  0.2569, -0.5344,  0.2549, -0.2179,\n",
      "         -0.8468,  0.0295, -0.2974, -0.6859,  0.2188,  0.4625,  0.9800, -0.9946]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n",
      "Embedding shape: torch.Size([1, 13, 768])\n",
      "Embedding shape of [CLS]: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "example = claims_train[0]\n",
    "print(f\"Example Claim: {example['claim']}\")\n",
    "\n",
    "inputs = tokenizer(example['claim'], return_tensors=\"pt\", padding=True, truncation=True, add_special_tokens=True) # add [CLS] token\n",
    "print(f\"Input Tokens: {inputs} of length {inputs.input_ids.shape}\")\n",
    "\n",
    "outputs = bert(**inputs)\n",
    "print(f\"Bert Output: {outputs}\")\n",
    "\n",
    "embeddings = outputs.last_hidden_state\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "\n",
    "sentence_emb = outputs.last_hidden_state[:,0,:]\n",
    "print(f\"Embedding shape of [CLS]: {sentence_emb.shape}\")\n",
    "\n",
    "def get_sentence_emb(sent):\n",
    "    inputs = tokenizer(sent, return_tensors=\"pt\", padding=True, truncation=True, add_special_tokens=True)\n",
    "    return bert(**inputs).last_hidden_state[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4b4e91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:40<00:00,  4.99it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for claim in tqdm(claims_train):\n",
    "    claim['emb'] = get_sentence_emb(claim['claim'])\n",
    "\n",
    "for claim in tqdm(claims_dev):\n",
    "    claim['emb'] = get_sentence_emb(claim['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2d44f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 84537.02it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 200492.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for claim in tqdm(claims_train):\n",
    "    claim['doc_id'] = None\n",
    "for claim in tqdm(claims_dev):\n",
    "    claim['doc_id'] = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9249509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1069/5183 [06:05<23:26,  2.93it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/felix/nlp_lss_2022/homework/homework_11&12.ipynb Cell 21'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/felix/nlp_lss_2022/homework/homework_11%2612.ipynb#ch0000035vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m doc_id, doc \u001b[39min\u001b[39;00m tqdm(corpus\u001b[39m.\u001b[39mitems()):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/felix/nlp_lss_2022/homework/homework_11%2612.ipynb#ch0000035vscode-remote?line=1'>2</a>\u001b[0m     emb \u001b[39m=\u001b[39m get_sentence_emb(doc[\u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/felix/nlp_lss_2022/homework/homework_11%2612.ipynb#ch0000035vscode-remote?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m claim \u001b[39min\u001b[39;00m claims_train:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/felix/nlp_lss_2022/homework/homework_11%2612.ipynb#ch0000035vscode-remote?line=3'>4</a>\u001b[0m         curr_sim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdot(claim[\u001b[39m'\u001b[39m\u001b[39memb\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mflatten(), emb\u001b[39m.\u001b[39mflatten())\n",
      "\u001b[1;32m/home/felix/nlp_lss_2022/homework/homework_11&12.ipynb Cell 18'\u001b[0m in \u001b[0;36mget_sentence_emb\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/felix/nlp_lss_2022/homework/homework_11%2612.ipynb#ch0000029vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_sentence_emb\u001b[39m(sent):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/felix/nlp_lss_2022/homework/homework_11%2612.ipynb#ch0000029vscode-remote?line=16'>17</a>\u001b[0m     inputs \u001b[39m=\u001b[39m tokenizer(sent, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, add_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/felix/nlp_lss_2022/homework/homework_11%2612.ipynb#ch0000029vscode-remote?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m bert(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\u001b[39m.\u001b[39mlast_hidden_state[:,\u001b[39m0\u001b[39m,:]\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=986'>987</a>\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=988'>989</a>\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=989'>990</a>\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=990'>991</a>\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=993'>994</a>\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=994'>995</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=995'>996</a>\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=996'>997</a>\u001b[0m     embedding_output,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=997'>998</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=998'>999</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=999'>1000</a>\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1000'>1001</a>\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1001'>1002</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1002'>1003</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1003'>1004</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1004'>1005</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1005'>1006</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1006'>1007</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1007'>1008</a>\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1008'>1009</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=575'>576</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=576'>577</a>\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=577'>578</a>\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=581'>582</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=582'>583</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=583'>584</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=584'>585</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=585'>586</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=586'>587</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=587'>588</a>\u001b[0m         layer_head_mask,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=588'>589</a>\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=589'>590</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=590'>591</a>\u001b[0m         past_key_value,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=591'>592</a>\u001b[0m         output_attentions,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=592'>593</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=594'>595</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=595'>596</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=459'>460</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=460'>461</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=461'>462</a>\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=468'>469</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=469'>470</a>\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=470'>471</a>\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=471'>472</a>\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=472'>473</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=473'>474</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=474'>475</a>\u001b[0m         head_mask,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=475'>476</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=476'>477</a>\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=477'>478</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=478'>479</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=480'>481</a>\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:411\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=391'>392</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=392'>393</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=393'>394</a>\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=399'>400</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=400'>401</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=401'>402</a>\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself(\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=402'>403</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=403'>404</a>\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=408'>409</a>\u001b[0m         output_attentions,\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=409'>410</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=410'>411</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(self_outputs[\u001b[39m0\u001b[39;49m], hidden_states)\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=411'>412</a>\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=412'>413</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:361\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=359'>360</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states, input_tensor):\n\u001b[0;32m--> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=360'>361</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=361'>362</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=362'>363</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/felix/miniconda3/envs/nlp_lss/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for doc_id, doc in tqdm(corpus.items()):\n",
    "    emb = get_sentence_emb(doc['title'])\n",
    "    for claim in claims_train:\n",
    "        curr_sim = torch.dot(claim['emb'].flatten(), emb.flatten())\n",
    "\n",
    "        # replace if curr_sim is higher\n",
    "        if claim[\"doc_id\"] is None or curr_sim > claim[\"doc_id\"][1]:\n",
    "            claim[\"doc_id\"] = (doc_id, curr_sim)\n",
    "            \n",
    "\n",
    "    for claim in claims_dev:\n",
    "        curr_sim = torch.dot(claim['emb'].flatten(), emb.flatten())\n",
    "\n",
    "        # replace if curr_sim is higher\n",
    "        if claim[\"doc_id\"] is None or curr_sim > claim[\"doc_id\"][1]:\n",
    "            claim[\"doc_id\"] = (doc_id, curr_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db2f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO evaluate your system. \n",
    "# If it operates on document level, we suggest to evaluate your system with k=3, k=5, k=10 retrieved documents\n",
    "\n",
    "# else, evaluate it using some reasonable method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c45f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your results, we suggest for k=3, which makes the rest of this exercise less time consuming\n",
    "\n",
    "k=3\n",
    "for claim in claims_train:\n",
    "    result = retrieve(claim[\"claim\"], corpus, k)\n",
    "    claim[\"doc_ids\"] = result\n",
    "\n",
    "for claim in claims_dev:\n",
    "    result = retrieve(claim[\"claim\"], corpus, k)\n",
    "    claim[\"doc_ids\"] = result\n",
    "    \n",
    "import json\n",
    "with open(\"data/claims_train_with_retrieved_documents.jsonl\", \"w\") as outfile:\n",
    "    for claim in claims_train:\n",
    "        json.dump(claim, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(\"data/claims_dev_with_retrieved_documents.jsonl\", \"w\") as outfile:\n",
    "    for claim in claims_dev:\n",
    "        json.dump(claim, outfile)\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8ad7a",
   "metadata": {},
   "source": [
    "**Sentence Retrieval**\n",
    "\n",
    "Now, we have candidate documents for every claim. As we have seen before, the precision achieved is not very convincing. So, we train a second module which takes a claim and a sentence as input and decides whether this sentence is possible evidence which supports or verifies the claim. This is just another pairwise sentence classification task and is usually tackled as a binary classification.\n",
    "\n",
    "* If you want to train your own model on CPU, we suggest to use [distilbert](https://huggingface.co/distilroberta-base) (which took me 20 minutes to fine-tune for one epoch on CPU). If you have access to GPUs, there's a variety of models to choose from, e.g. [here](https://huggingface.co/transformers/pretrained_models.html) or [here](https://huggingface.co/models).\n",
    "\n",
    "* We also provide a model [here](https://www.dropbox.com/s/mh3lrg3z626d0xw/scibert_model.zip?dl=0) which is a BertForSequenceClassification checkpoint fine-tuned from [SciBERT](https://huggingface.co/allenai/scibert_scivocab_uncased) which you could use in this task. The model is trained to predict class 1 for annotated evidence sentences and class 0 for randomly sampled negative examples. You can download this model with \n",
    "\n",
    "* wget https://www.dropbox.com/s/mh3lrg3z626d0xw/scibert_model.zip?dl=0\n",
    "\n",
    "* You can use any other model/method you like if you think it works reasonably well on this specific task\n",
    "\n",
    "* We again provide a random baseline for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b9251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random baseline\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "for claim in tqdm(claims_dev):\n",
    "    doc_ids = claim[\"doc_ids\"]\n",
    "    predicted_evidence = {}\n",
    "    for doc_id in doc_ids:\n",
    "        sentences = corpus[doc_id][\"abstract\"]\n",
    "        predictions = np.random.normal(loc=-1, size=len(sentences))\n",
    "        predicted_sentences = [i for i,j in enumerate(predictions) if j > 0]\n",
    "        if predicted_sentences:\n",
    "            predicted_evidence[doc_id] = {\"sentences\": predicted_sentences}\n",
    "    claim[\"predicted_evidence\"] = predicted_evidence\n",
    "\n",
    "with open(\"data/claims_dev_with_predicted_sentences.jsonl\", \"w\") as outfile:\n",
    "    for claim in claims_dev:\n",
    "        json.dump(claim, outfile)\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO for every claim in the development set, and for every sentence in each retrieved abstract\n",
    "#predict whether it is evidence or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0bac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utils to evalaute this using the official metrics for SciFact\n",
    "from collections import Counter\n",
    "def safe_divide(num, denom):\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return num / denom\n",
    "\n",
    "def compute_f1(counts, difficulty=None):\n",
    "    correct_key = \"correct\" if difficulty is None else f\"correct_{difficulty}\"\n",
    "    precision = safe_divide(counts[correct_key], counts[\"retrieved\"])\n",
    "    recall = safe_divide(counts[correct_key], counts[\"relevant\"])\n",
    "    f1 = safe_divide(2 * precision * recall, precision + recall)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "def is_correct(pred_sentence, pred_sentences, gold_sets):\n",
    "    \"\"\"\n",
    "    A predicted sentence is correctly identified if it is part of a gold\n",
    "    rationale, and all other sentences in the gold rationale are also\n",
    "    predicted rationale sentences.\n",
    "    \"\"\"\n",
    "    for gold_set in gold_sets:\n",
    "        gold_sents = gold_set[\"sentences\"]\n",
    "        if pred_sentence in gold_sents:\n",
    "            if all([x in pred_sentences for x in gold_sents]):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def evaluate_sentence_retrieval(dataset, rationale_selection):\n",
    "    counts = Counter()\n",
    "    for data, retrieval in zip(dataset, rationale_selection):\n",
    "        assert data['id'] == retrieval['id']\n",
    "\n",
    "        # Count all the gold evidence sentences.\n",
    "        for doc_key, gold_rationales in data[\"evidence\"].items():\n",
    "            for entry in gold_rationales:\n",
    "                counts[\"relevant\"] += len(entry[\"sentences\"])\n",
    "\n",
    "        claim_id = retrieval['id']\n",
    "        for doc_id, pred_sentences in retrieval['predicted_evidence'].items():\n",
    "            true_evidence_sets = data['evidence'].get(doc_id) or []\n",
    "            for pred_sentence in pred_sentences:\n",
    "                counts[\"retrieved\"] += 1\n",
    "                if is_correct(pred_sentence, pred_sentences, true_evidence_sets):\n",
    "                    counts[\"correct\"] += 1\n",
    "    f1 = compute_f1(counts)\n",
    "    print(f1)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f48511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate \n",
    "evaluate_sentence_retrieval(claims_dev, claims_dev)\n",
    "# and we find that our random baseline behaves poorly :(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO evaluate your predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a4a3a",
   "metadata": {},
   "source": [
    "**Part 2 of the Assignment: Claim Verification**\n",
    "\n",
    "To recap: For every claim, we have retrieved possible evidence sentence. Now, we want to determine whether these sentences support or contradict a claim. Usually, this is handled via textual entailment; if the evidence entails the claim, it is supported (and else, it is contradicted). For this task, you should train your own model, we propose to start from a [distilbert checkpoint](https://huggingface.co/typeform/distilbert-base-uncased-mnli) which has been pre-trained on MNLI. \n",
    "\n",
    "Again, we provide a random baseline and evaluate this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf86ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random baseline\n",
    "\n",
    "id2label = {0:\"SUPPORT\", 1: \"NOT_ENOUGH_INFO\", 2:\"CONTRADICT\"}\n",
    "for claim in claims_dev:\n",
    "    predicted_evidence = claim[\"predicted_evidence\"]\n",
    "    labels = {}\n",
    "    for doc_id, sentence_ids in predicted_evidence.items():\n",
    "        abstract = corpus[doc_id][\"abstract\"]\n",
    "        sentences = \" \".join(abstract[i] for i in sentence_ids[\"sentences\"])\n",
    "        label = id2label[np.random.choice([0,1,2])]\n",
    "        # if we predict neutral, we just ignore these evidence sentences\n",
    "        labels[doc_id] = {\"label\": label}\n",
    "    claim[\"labels\"] = labels\n",
    "            \n",
    "        \n",
    "claims_dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c6737",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO create an appropriate dataset to fine-tune your model \n",
    "# (input to your model should be [CLS] claim [SEP] evidence_sentence [SEP]\n",
    "# it might be required to sample some evidence sentences which are not annotated and act as \"neutral\" or \n",
    "# \"NOT_ENOUGH_INFO\" examples\n",
    "# (hint: labels in mnli are: LABELS = {'CONTRADICT': 0, 'NOT_ENOUGH_INFO': 1, 'SUPPORT': 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utils to evalaute this using the official metrics for SciFact\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "def evaluate_labels(dataset, label_prediction):\n",
    "    LABELS = {'CONTRADICT': 0, 'NOT_ENOUGH_INFO': 1, 'SUPPORT': 2}\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "\n",
    "    for data, prediction in zip(dataset, label_prediction):\n",
    "        assert data['id'] == prediction['id']\n",
    "\n",
    "        if not prediction['labels']:\n",
    "            continue\n",
    "\n",
    "        claim_id = data['id']\n",
    "        for doc_id, pred in prediction['labels'].items():\n",
    "            pred_label = pred['label']\n",
    "            true_label = {es['label'] for es in data['evidence'].get(doc_id) or []}\n",
    "            assert len(true_label) <= 1, 'Currently support only one label per doc'\n",
    "            true_label = next(iter(true_label)) if true_label else 'NOT_ENOUGH_INFO'\n",
    "            pred_labels.append(LABELS[pred_label])\n",
    "            true_labels.append(LABELS[true_label])\n",
    "\n",
    "    print(f'Accuracy           {round(sum([pred_labels[i] == true_labels[i] for i in range(len(pred_labels))]) / len(pred_labels), 4)}')\n",
    "    print(f'Macro F1:          {f1_score(true_labels, pred_labels, average=\"macro\").round(4)}')\n",
    "    print(f'Macro F1 w/o NEI:  {f1_score(true_labels, pred_labels, average=\"macro\", labels=[0, 2]).round(4)}')\n",
    "    print()\n",
    "    print('                   [C      N      S     ]')\n",
    "    print(f'F1:                {f1_score(true_labels, pred_labels, average=None).round(4)}')\n",
    "    print(f'Precision:         {precision_score(true_labels, pred_labels, average=None).round(4)}')\n",
    "    print(f'Recall:            {recall_score(true_labels, pred_labels, average=None).round(4)}')\n",
    "    print()\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(true_labels, pred_labels))\n",
    "evaluate_labels(claims_dev, claims_dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO evaluate your own predictions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83566c18858e8142d27dbb7eae678c7bccb649f3b4cd52ece9b91eea6305cb56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('nlp_lss')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
